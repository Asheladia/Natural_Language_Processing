{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructor Do: Terms Relevance (Understanding TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Text from the Reuters Dataset\n",
    "\n",
    "To demonstrate how TF-IDF works, we will use the _Reuters_ dataset that is bundled in NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     C:\\Users\\mshel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download/update the Reuters dataset\n",
    "nltk.download(\"reuters\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of docs in the corpus: 10788\n"
     ]
    }
   ],
   "source": [
    "# Count the total number of documents in the collection\n",
    "doc_ids = reuters.fileids()\n",
    "print(f\"Total number of docs in the corpus: {len(doc_ids)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Bag of Words from a Single Document\n",
    "\n",
    "We select a single document from the corpus to get it's \"Bag of Words\". The same can be done from multiple documents by pasing a list of documents (or documents ids on this example) to the `CountVectorizer()` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DUTCH ADJUSTED UNEMPLOYMENT RISES IN MARCH\n",
      "  Dutch seasonally adjusted unemployment\n",
      "  rose in the month to end-March to a total 693,000 from 690,600\n",
      "  at end-February, but was well down from 730,100 at end-March\n",
      "  1986, Social Affairs Ministry figures show.\n",
      "      The figure for male jobless rose by 2,000 in the month to\n",
      "  436,500 compared with 470,700 a year earlier. The figure for\n",
      "  women was 256,500 at end-March against 256,100 a month earlier\n",
      "  and 259,400 at end-March 1986.\n",
      "      On an unadjusted basis total unemployment fell by 16,500 in\n",
      "  the month to end-March to 692,200. In March 1986 the figure was\n",
      "  725,000.\n",
      "      A ministry spokesman said the unadjusted figures showed a\n",
      "  smaller than usual seasonal decrease for the time of year,\n",
      "  because of particularly cold weather delaying work in the\n",
      "  building industry. He said this explained the increase in the\n",
      "  adjusted statistics.\n",
      "      Total vacancies available rose by 1,900 to 26,300 at\n",
      "  end-March. A year earlier the figure was 28,763.\n",
      "  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select and print the original single document text\n",
    "doc_id = \"test/15045\"\n",
    "doc_text = reuters.raw(doc_id)\n",
    "print(doc_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000', '100', '16', '1986', '200', '256', '259', '26', '28', '300', '400', '436', '470', '500', '600', '690', '692', '693', '700', '725', '730', '763', '900', 'adjusted', 'affairs', 'available', 'basis', 'building', 'cold', 'compared', 'decrease', 'delaying', 'dutch', 'earlier', 'end', 'explained', 'february', 'fell', 'figure', 'figures', 'increase', 'industry', 'jobless', 'male', 'march', 'ministry', 'month', 'particularly', 'rises', 'rose', 'said', 'seasonal', 'seasonally', 'showed', 'smaller', 'social', 'spokesman', 'statistics', 'time', 'total', 'unadjusted', 'unemployment', 'usual', 'vacancies', 'weather', 'women', 'work', 'year']\n"
     ]
    }
   ],
   "source": [
    "# Creating the CountVectorizer instance defining the stopwords in English to be ignored\n",
    "vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "# Getting the tokenization and occurrence counting\n",
    "X = vectorizer.fit_transform([doc_text])\n",
    "\n",
    "# Retrieve unique words list\n",
    "words = vectorizer.get_feature_names()\n",
    "print(words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X raw data contains the occurrence of each term in the document. A unique ID is assigned to each term.\n",
    "print(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Word_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1986</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>256</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>436</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>470</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>690</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>693</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>725</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>730</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>763</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>adjusted</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>affairs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>available</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>basis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>building</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>cold</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>compared</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>figure</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>figures</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>increase</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>industry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>jobless</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>march</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>ministry</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>month</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>particularly</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>rises</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>rose</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>said</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>seasonal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>seasonally</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>showed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>smaller</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>social</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>spokesman</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>statistics</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>time</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>total</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>unadjusted</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>unemployment</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>usual</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>vacancies</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>weather</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>women</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>work</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>year</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Word  Word_Count\n",
       "0            000           3\n",
       "1            100           2\n",
       "2             16           1\n",
       "3           1986           3\n",
       "4            200           1\n",
       "5            256           2\n",
       "6            259           1\n",
       "7             26           1\n",
       "8             28           1\n",
       "9            300           1\n",
       "10           400           1\n",
       "11           436           1\n",
       "12           470           1\n",
       "13           500           3\n",
       "14           600           1\n",
       "15           690           1\n",
       "16           692           1\n",
       "17           693           1\n",
       "18           700           1\n",
       "19           725           1\n",
       "20           730           1\n",
       "21           763           1\n",
       "22           900           1\n",
       "23      adjusted           3\n",
       "24       affairs           1\n",
       "25     available           1\n",
       "26         basis           1\n",
       "27      building           1\n",
       "28          cold           1\n",
       "29      compared           1\n",
       "..           ...         ...\n",
       "38        figure           4\n",
       "39       figures           2\n",
       "40      increase           1\n",
       "41      industry           1\n",
       "42       jobless           1\n",
       "43          male           1\n",
       "44         march           8\n",
       "45      ministry           2\n",
       "46         month           4\n",
       "47  particularly           1\n",
       "48         rises           1\n",
       "49          rose           3\n",
       "50          said           2\n",
       "51      seasonal           1\n",
       "52    seasonally           1\n",
       "53        showed           1\n",
       "54       smaller           1\n",
       "55        social           1\n",
       "56     spokesman           1\n",
       "57    statistics           1\n",
       "58          time           1\n",
       "59         total           3\n",
       "60    unadjusted           2\n",
       "61  unemployment           3\n",
       "62         usual           1\n",
       "63     vacancies           1\n",
       "64       weather           1\n",
       "65         women           1\n",
       "66          work           1\n",
       "67          year           3\n",
       "\n",
       "[68 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the bag of words as DataFrame\n",
    "words_df = pd.DataFrame(\n",
    "    list(zip(words, np.ravel(X.sum(axis=0)))), columns=[\"Word\", \"Word_Count\"]\n",
    ")\n",
    "words_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the TF-IDF from a Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the corpus (first 1000 files from Reuters dataset)\n",
    "all_docs_id = reuters.fileids()\n",
    "corpus_id = all_docs_id[0:1000]\n",
    "corpus = [reuters.raw(doc) for doc in corpus_id]\n",
    "\n",
    "# Print sample document\n",
    "print(corpus[50])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "X_corpus = vectorizer.fit_transform(corpus)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting matrix info\n",
    "print(f\"Matrix shape: {X_corpus.shape}\")\n",
    "print(f\"Total number of documents: {X_corpus.shape[0]}\")\n",
    "print(f\"Total number of unique words (tokens): {X_corpus.shape[1]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve words list from corpus\n",
    "words_corpus = vectorizer.get_feature_names()\n",
    "print(words_corpus)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the TF-IDF weight of each word in corpus as DataFrame\n",
    "words_corpus_df = pd.DataFrame(\n",
    "    list(zip(words_corpus, np.ravel(X_corpus.mean(axis=0)))), columns=[\"Word\", \"TF-IDF\"]\n",
    ")\n",
    "\n",
    "words_corpus_df = words_corpus_df.sort_values(by=[\"TF-IDF\"], ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highest 10 TF-IDF scores\n",
    "words_corpus_df.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowest 10 TF-IDF scores\n",
    "words_corpus_df.tail(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python [conda env:alpacaenv] *",
   "language": "python",
   "name": "conda-env-alpacaenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
